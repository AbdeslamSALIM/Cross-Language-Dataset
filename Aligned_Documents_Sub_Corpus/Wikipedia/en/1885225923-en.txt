Simpson's paradox (or the Yule-Simpson effect) is a statistical paradox wherein the successes of groups seem reversed when the groups are combined. This result is often encountered in social and medical science statistics, and occurs when frequency data are hastily given causal interpretation Judea Pearl. Causality: Models, Reasoning, and Inference, Cambridge University Press, 2000. ISBN 0-521-77362-8.; the paradox disappears when causal relations are derived systematically, through formal analysis.Though mostly unknown to laymen, Simpson's Paradox is well known to statisticians, and is described in several introductory statistics books.David Freedman, Robert Pisani and Roger Purves. Statistics (3rd edition). W.W. Norton, 1998, p. 19. ISBN 0-393-97083-3.David S. Moore and D.S. George P. McCabe (February 2005). "Introduction to the Practice of Statistics" (5th edition). W.H. Freeman & Company. ISBN 071676282X. Many statisticians believe that the mainstream public should be apprised of counterintuitive results such as Simpson's paradox,Robert L. Wardrop (February 1995). "Simpson's Paradox and the Hot Hand in Basketball". The American Statistician, ' 49 (1)': pp. 24–28. in particular to caution against the inference of causal relationships based on the association between two variables.Alan Agresti (2002). "Categorical Data Analysis" (Second edition). John Wiley and Sons. ISBN 0-471-36093-7Edward H. Simpson described the phenomenon in 1951, along with Karl Pearson et al.,  and Udny Yule in 1903. The name Simpson's paradox was coined by Colin R. Blyth in 1972. Since Simpson did not discover this statistical paradox, some authors, instead, have used the impersonal names reversal paradox and amalgamation paradox in referring to what is now called Simpson's Paradox and the Yule-Simpson effect.Examples=== Batting averages === A common example of the paradox involves batting averages in baseball: it is possible for one player to hit for a higher batting average than another player during a given year, and to do so again during the next year, but to have a lower batting average when the two years are combined. This phenomenon, which occurs when there are large differences in the number of at-bats between years, is well-known among sports sabermetricians such as Bill James.A real-life example is provided by Ken RossKen Ross. "A Mathematician at the Ballpark: Odds and Probabilities for Baseball Fans (Paperback)" Pi Press, 2004. ISBN 0131479903. 12–13 and involves the batting average of baseball players Derek Jeter and David Justice during the years 1995 and 1996:Statistics available from http://www.baseball-reference.com/ : Data for Derek Jeter, Data for David Justice.19951996CombinedDerek Jeter12/48.250183/582.314195/630.310David Justice104/411.25345/140.321149/551.270In both 1995 and 1996, Justice had a higher batting average (in bold) than Jeter; however, when the two years are combined, Jeter shows a higher batting average than Justice. According to Ross, this phenomenon would be observed about once per year among the interesting baseball players. In this particular case, the paradox can still be observed if the year 1997 is also taken into account:199519961997CombinedDerek Jeter12/48.250183/582.314190/654.291385/1284.300David Justice104/411.25345/140.321163/495.329312/1046.298=== Kidney stone treatment === This is a real-life example from a medical study comparing the success rates of two treatments for kidney stones.The first table shows the overall success rates and numbers of treatments for both treatments (where Treatment A includes all open procedures and Treatment B is percutaneous nephrolithotomy):Treatment ATreatment B78% (273/350)83% (289/350)This seems to show treatment B is more effective. If we include data about kidney stone size, however, the same set of treatments reveals a different answer:Treatment ATreatment BSmall StonesGroup 193% (81/87)Group 287% (234/270)Large StonesGroup 373% (192/263)Group 469% (55/80)Both78% (273/350)'''83% (289/350)The information about stone size has reversed our conclusion about the effectiveness of each treatment. Now treatment A is seen to be more effective in both cases. In this example the lurking variable (or confounding variable) of stone size was not previously known to be important until its effects were included.Which treatment is considered better is determined by an inequality between two ratios (successes/total). The reversal of the inequality between the ratios, which creates Simpson's paradox, happens because two effects occur together:The sizes of the groups, which are combined when the lurking variable is ignored, are very different. Doctors tend to give the severe cases (large stones) the better treatment (A), and the milder cases (small stones) the inferior treatment (B). Therefore, the totals are dominated by groups 3 and 2, and not by the two much smaller groups 1 and 4.The lurking variable has a large effect on the ratios, i.e. the success rate is more strongly influenced by the severity of the case than by the choice of treatment. Therefore, the group of patients with large stones using treatment A (group 3) does worse than the group with small stones, even if the latter used the inferior treatment B (group 2).Berkeley sex bias caseOne of the best known real life examples of Simpson's paradox occurred when the University of California, Berkeley was sued for bias against women applying to graduate school. The admission figures for fall 1973 showed that men applying were more likely than women to be admitted, and the difference was so large that it was unlikely to be due to chance..&lt;/ref&gt;&lt;ref name=&quot;freedman&quot;&gt;David Freedman, Robert Pisani and Roger Curves. Statistics (3rd edition). W.W. Norton, 1998. ISBN 0-393-97083-3.&lt;/ref&gt;Applicants% admittedMen844244%Women432135%However when examining the individual departments, it was found that no department was significantly biased against women; in fact, most departments had a small bias against men.MajorMenWomenApplicants% admittedApplicants% admittedA82562%10882%B56063%2568%C32537%59334%D41733%37535%E19128%39324%F2726%3417%The explanation turned out to be that women tended to apply to competitive departments with low rates of admission even among qualified applicants (such as English), while men tended to apply to less-competitive departments with high rates of admission among qualified applicants (such as engineering). The conditions under which department-specific frequency data constitute a proper defense against charges of discrimination are formulated in Pearl (2000).2006 US school studyIn July 2006, the United States Department of Education released a studyH. Braun, F. Jenkins and W. Grigg, (2006) &quot;Comparing Private Schools and Public Schools Using Hierarchical Linear Modeling, U.S. Department of Education, National Center for Education Statistics, Institute of Education Sciences, Washington, DC, United States Government Printing Office. documenting student performances in reading and math in different school settings.Diana Jean Schemo. "Public Schools Perform Near Private Ones in Study. The New York Times, 15 July 2006. Retrieved on 25 July 2007. It reported that while the math and reading levels for students at grades 4 and 8 were uniformly higher in private/parochial schools than in public schools, repeating the comparisons on demographic subgroups showed much smaller differences, which were nearly equally divided in direction.Low birth weight paradoxThe low birth weight paradox is an apparently paradoxical observation relating to the birth weights and mortality of children born to tobacco smoking mothers. Traditionally, babies weighing less than a certain amount (which varies between countries) have been classified as having low birth weight. In a given population, low birth weight babies have a significantly higher mortality rate than others. However, it has been observed that low birth weight children born to smoking mothers have a lower mortality rate than the low birth weight children of non-smokers.Wilcox, Allen (2006). "The Perils of Birth Weight — A Lesson from Directed Acyclic Graphs". American Journal of Epidemiology. 164(11):1121–1123.DescriptionSuppose two people, Lisa and Bart, each edit Wikipedia articles for two weeks. In the first week, Lisa improves 60 percent of the articles she edits out of 100 articles edited, and Bart improves 90 percent of the articles he edits out of 10 articles edited. In the second week, Lisa improves just 10 percent of the articles she edits out of 10 articles edited, while Bart improves 30 percent yet out of 100 articles edited.Week 1Week 2TotalLisa60/1001/1061/110Bart9/1030/10039/110Both times, Bart improved a higher percentage of the quantity of articles compared to Lisa, while Lisa improved a higher percentage of the quality of articles. When the two tests are combined using a weighted average, overall, Lisa has improved a much higher percentage than Bart because the quality modifier had a significantly higher percentage. Therefore, like other paradoxes, it only appears to be a paradox because of incorrect assumptions, incomplete or misguided information, or a lack of understanding a particular concept.Week 1 quantity percentageWeek 2 quantity percentageTotal quantity and weighted quality percentageLisa60%10%55.5%Bart90%30%35.5%This imagined paradox is caused when the percentage is provided but not the ratio by various media outlets. In this example, if only the 90% in the first week for Bart was provided but not the ratio (9:10), it would distort the information causing the imagined paradox. Even though Bart's percentage is higher for the first and second week, when two week's of articles is combined, overall Lisa had improved a greater proportion, 55% of the 110 total articles. Lisa's proportional total of articles improved exceeds Bart's total.Here are some notations:In the first weekS_L(1) = 60\% &mdash; Lisa improved 60% of the many articles she edited.S_B(1) = 90\% &mdash; Bart had a 90% success rate during that time.Success is associated with Bart.In the second weekS_L(2) = 10\% &mdash; Lisa managed 10% in her busy life.S_B(2) = 30\% &mdash; Bart achieved a 30% success rate.Success is associated with Bart.On both occasions Bart's edits were more successful than Lisa's. But if we combine the two sets, we see that Lisa and Bart both edited 110 articles, and:S_L = \begin\frac\end &mdash; Lisa improved 61 articles.S_B = \begin\frac\end &mdash; Bart improved only 39.S_L  S_B \, &mdash; Success is now associated with Lisa.Bart is better for each set but worse overall.The paradox stems from our healthy intuition that Bart could not possibly be a better editor on each set but worse overall. Pearl (2000) in fact proved the impossibility of such happening, where "better editor" is taken in the counterfactual sense: "Were Bart to edit all items in a set he would do better than Lisa would, on those same items." Clearly, frequency data cannot support this sense of "better editor," because it does not tell us how Bart would perform on items edited by Lisa, and vice versa. In the back of our mind, though, we assume that the articles were assigned at random to Bart and Lisa, an assumption which (for large sample) would support the counterfactual interpretation of "better editor." However, under random assignment conditions, the data given in this example is impossible, which accounts for our surprise when confronting the rate reversal.The arithmetical basis of the paradox is uncontroversial. If S_B(1)  S_L(1) and S_B(2)  S_L(2) we feel that S_B must be greater than S_L. However if different weights are used to form the overall score for each person then this feeling may be disappointed. Here the first test is weighted \begin\frac\end for Lisa and \begin\frac\end for Bart while the weights are reversed on the second test.S_L = \begin\frac\endS_L(1) + \begin\frac\endS_L(2)S_B = \begin\frac\endS_B(1) + \begin\frac\endS_B(2)By more extreme reweighting Lisa's overall score can be pushed up towards 60% and Bart's down towards 30%.Lisa is a better editor on average, as her overall success rate is higher. But it is possible to have told the story in a way which would make it appear obvious that Bart is more diligent.Simpson's paradox shows us an extreme example of the importance of including data about possible confounding variables when attempting to calculate causal relations. Precise criteria for selecting a set of "confounding variables," (i.e., variables that yield correct causal relationships if included in the analysis), is given in (Pearl, 2000) using causal graphs.While Simpson's paradox often refers to the analysis of count tables, as shown in this example, it also occurs with continuous data:John Fox (1997). "Applied Regression Analysis, Linear Models, and Related Methods". Sage Publications. ISBN 080394540X. 136–137 for example, if one fits separated regression lines through two sets of data, the two regression lines may show a positive trend, while a regression line fitted through all data together will show a negative trend, as shown on the picture above.Vector interpretationSimpson's paradox can also be illustrated using the 2-dimensional vector space.Jerzy Kocik (December 2001). Proofs without Words: Simpson's Paradox. Mathematics Magazine. 74 (5), p. 399. A success rate of p/q can be represented by a vector \overrightarrow=(q,p), with a slope of p/q. If two rates p_1/q_1 and p_2/q_2 are combined, as in the examples given above, the result can be represented by the sum of the vectors (q_1, p_1) and (q_2, p_2), which according to the parallelogram rule is the vector (q_1+q_2, p_1+p_2), with slope \frac.Simpson's paradox says that even if a vector \overrightarrow (in blue in the figure) has a smaller slope than another vector \overrightarrow (in red), and \overrightarrow has a smaller slope than \overrightarrow, the sum of the two vectors \overrightarrow + \overrightarrow (indicated by "+" in the figure) can still have a larger slope than the sum of the two vectors \overrightarrow + \overrightarrow, as shown in the example.ReferencesExternal linksStanford Encyclopedia of Philosophy: " Simpson's Paradox" -- by Gary Malinas.For a brief history of the origins of the paradox see the entries "Simpson's Paradox and Spurious Correlation" inEarliest known uses of some of the words of mathematics: SPearl, Judea, "&quot;The Art and Science of Cause and Effect." A slide show and tutorial lecture.Pearl, Judea, "Simpson's Paradox: An Anatomy."Short articles by Alexander Bogomolny at cut-the-knot:"Mediant Fractions.""Simpson's Paradox."Category:Probability theory paradoxes Category:Statistical paradoxesde:Simpson-Paradoxon es:Paradoja de Simpson fr:Paradoxe de Simpson it:Paradosso di Simpson hu:Simpson-paradoxon nl:Simpsons paradox ja:シンプソンのパラドックス pl:Paradoks Simpsona ru:Парадокс Симпсона sk:Simpsonov paradox zh:辛普森悖论