\; \exp\left(-\frac \right) \!&lt;/math&gt;|
 cdf        =&lt;math&gt;\frac12 \left(1 + \mathrm\,\frac\right) \!&lt;/math&gt;|
 mean       =&lt;math&gt;\mu&lt;/math&gt;|
 median     =&lt;math&gt;\mu&lt;/math&gt;|
 mode       =&lt;math&gt;\mu&lt;/math&gt;|
 variance   =&lt;math&gt;\sigma^2&lt;/math&gt;|
 skewness   = 0|
 kurtosis   = 3 (0 si normalisé)|
 entropy    =&lt;math&gt;\ln\left(\sigma\sqrt\right)\!&lt;/math&gt;|
 mgf        =&lt;math&gt;M_X(t)= \exp\left(\mu\,t+\sigma^2 \frac\right)&lt;/math&gt;|
 char       =&lt;math&gt;\phi_X(t)=\exp\left(\mu\,i\,t-\frac\right)&lt;/math&gt;| En probabilité, une variable aléatoire suit une loi normale (ou loi normale gaussienne, loi de Laplace-Gauss) d'espérance μ'' et d'écart type \sigma (donc de variance \sigma^2) si elle admet une densité de probabilité ''f telle que :f(x)=\frac\mathrm^\left(\frac\right)^2Une telle variable aléatoire est dite variable gaussienne.Elle est notée habituellement X \sim \mathcal(\mu,\, \sigma^2) on a aussi utilisé la notation \mathcal(\mu,\, \sigma), mais cette notation, qui n'est pas cohérente avec la notation habituelle de la loi (multi-)normale sur \ \R^n, tend à céder la place à la notation "classique" \mathcal(\mu,\, \sigma^2) La loi normale est une des principales distributions de probabilité. Elle a été introduite par le mathématicien Abraham de Moivre en 1733 et utilisée par lui afin d'approcher des probabilités associées à des variables aléatoires binomiales possédant un paramètre n'' très grand. Cette loi a été mise en évidence par Gauss au  et permet de modéliser de nombreuses études biométriques. Sa densité de probabilité dessine une courbe dite '''courbe en cloche' ou courbe de Gauss.La loi normale centrée réduiteLa fonction \varphi : \R \to \R^+ définie par :\varphi(t)=\frac\, \mathrm^est une densité de probabilité : elle est continue, et son intégrale sur \ \R est égale à 1.On sait en effet que \ \int_^\mathrm^\ dt = \sqrt (intégrale de Gauss).On démontre (voir plus bas) que la loi définie par cette densité de probabilité admet une espérance nulle et une variance égale à 1.Remarques :la densité \ \varphi est paire ;elle est indéfiniment dérivable et vérifie, pour tout \ t \in \R, l'identité \varphi'(t) = - t\, \varphi(t).DéfinitionOn appelle loi normale (ou gaussienne) centrée réduite la loi définie par la densité de probabilité \varphi.La représentation graphique de cette densité est une courbe en cloche (ou courbe de Gauss).MomentsLes moments de cette loi existent tous. Pour tout \ n \in \mathbb, le moment d'ordre n par rapport à l'origine est :\ m_n = \int_^ t^n\, \varphi(t)\, dt.Pour la suite on supposera \mu = 0 et \sigma^=1.En raison de la parité de l'intégrande, tous les moments d'ordre impair sont nuls : m_ = 0Supposons à présent n pair : \ n = 2\, k, où \ k \in \mathbb.Si \ k \geq 1, une intégration par parties (non détaillée ici) donne :m_ = \int_^ t^\, t\, \varphi(t)\, dt =-\int_^ t^\, \varphi'(t)\, dt = (2\, k - 1) \int_^ t^\, \varphi(t)\, dtce qui fournit la relation de récurrence :m_ = (2\, k - 1)\, m_ .De cette relation, on déduit, comme \ m_0 = 1\,, que :m_ = 1 \cdot 3 \cdots (2\, k - 1) = \fracEn particulier, \ m_1 = 0 (l'espérance est nulle : la loi est donc dite centrée) et \ m_2 = 1\, (la variance vaut \ \ m_2 - m_1^2 = 1\,\! : la loi est donc dite réduite).Ceci justifie l'appellation de loi normale centrée réduite.Des formules précédentes, on déduit encore :m_3 = 0\, &nbsp;et &nbsp;m_4 = 3\,La loi étant réduite, les moments centrés sont tous égaux aux moments par rapport à l'origine de même rang ; en particulier :\mu_2 = \sigma^2 = 1\,, &nbsp;\mu_3 = 0\, et \mu_4 = 3 \sigma^4 \,.On en déduit l'asymétrie (skewness) : \gamma_1 = \frac = 0\, et l'aplatissement (kurtosis) : \beta_2 = \frac = 3\,.Fonction de répartition On note \Phi la fonction de répartition de la loi normale centrée réduite. Elle est définie, pour tout réel x, par :\ \Phi(x) = \int_^x \varphi(t)\, dt = \int_^x\frac\,\mathrm^\, dt .C'est la primitive de \varphi qui tend vers 0 en -\infty ; elle ne s'exprime pas à l'aide des fonctions usuelles (exponentielle, etc.) mais devient elle-même une fonction usuelle, importante, pour quiconque pratique le calcul des probabilités ou les statistiques ; elle s'exprime à l'aide de la fonction d'erreur.Citons les propriétés suivantes de la fonction \Phi :Elle est indéfiniment dérivable, et \Phi' = \varphiElle est strictement croissante, tend vers 0 en -\infty et vers 1 en +\infty(c'est donc une bijection \R \to\, ]0,\, 1: pour tout &lt;math&gt;p \in\, 0,\, 1[\,, il existe  x \in \R unique, noté \ \Phi^(p), tel que \ \Phi(x) = p)Pour tout  x \in \R, \Phi(-x) = 1 - \Phi(x) (ceci résulte de ce que la densité est paire) ; en particulier, \ \Phi(0) = 0,5Remarque : les notations \varphi et \ \Phi pour désigner « la » densité et la fonction de répartition de la loi normale centrée réduite sont usuelles.Approximation de la fonction de répartitionIl n'existe pas d'expression pour \Phi mais on peut exploiter avec profit son aspect régulier pour en donner une approximation grâce à un développement en série de Taylor. Par exemple, voici une approximation (à l'ordre 5) autour de 0: \Phi(x) \approx \frac + 0,3989423 \leftx-\frac+\frac\right. Cette approximation est performante pour |x|.Tables numériquesIl existe des tables de la fonction de répartition, donnant des valeurs approchées de \ \Phi(x) ; on se limite à des x positifs ou nuls : en effet, si par exemple on connaît l'approximation \Phi(0,5) \simeq 0,6915, on en déduit \Phi(-0,5) \simeq 1 - 0,6915 = 0,3085.Au lieu des précédentes, on utilise souvent des tables de la fonction qu'on notera ici \ \Phi_0, définie sur \ \R^+ par :\Phi_0(x) =\int_0^x \varphi(t)\, dtLa table suivante donne pour tout x de 0 jusqu'à 3,9 par pas de 0,01, la valeur de 105 \Phi(x). Ces valeurs sont arrondies à l'unité la plus proche.L'entrée en ligne donne les deux premiers chiffres de x, c'est-à-dire le chiffre des unités et celui des dixièmes, et l'entrée en colonne le chiffre des centièmes.Par exemple : \Phi(1,73)=0,95818.0,000,010,020,030,040,050,060,070,080,090,0500005039950798511975159551994523925279053188535860,1539835438054776551725556755962563565674957142575350,2579265831758706590955948359871602576064261026614090,3617916217262552629306330763683640586443164803651730,4655426591066276666406700367364677246808268439687930,5691466949769847701947054070884712267156671904722400,6725757290773237735657389174215745377485775175754900,7758047611576424767307703577337776377793578230785240,8788147910379389796737995580234805118078581057813270,9815948185982121823818263982894831478339883646838911,0841348437584614848498508385314855438576985993862141,1864338665086864870768728687493876988790088100882981,2884938868688877890658925189435896178979689973901471,3903209049090658908249098891149913099146691621917741,4919249207392220923649250792647927859292293056931891,5933199344893574936999382293943940629417994295944081,6945209463094738948459495095053951549525495352954491,7955439563795728958189590795994960809616496246963271,8964079648596562966389671296784968569692696995970621,9971289719397257973209738197441975009755897615976702,0977259777897831978829793297982980309807798124981692,1982149825798300983419838298422984619850098537985742,2986109864598679987139874598778988099884098870988992,3989289895698983990109903699061990869911199134991582,4991809920299224992459926699286993059932499343993612,5993799939699413994309944699461994779949299506995202,6995349954799560995739958599598996099962199632996432,7996539966499674996839969399702997119972099728997362,8997449975299760997679977499781997889979599801998072,9998139981999825998319983699841998469985199856998613,0998659986999874998789988299886998899989399896999003,1999039990699910999139991699918999219992499926999293,2999319993499936999389994099942999449994699948999503,3999529995399955999579995899960999619996299964999653,4999669996899969999709997199972999739997499975999763,5999779997899978999799998099981999819998299983999833,6999849998599985999869998699987999879998899988999893,7999999999999999999999999999999999999999999999999993,8999999999999999999999999999999999999999999999999993,91.00001.00001.00001.00001.00001.00001.00001.00001.00001.0000On dispose des relations simples suivantes entre \ \Phi et \ \Phi_0 (découlant de la formule de Chasles pour les intégrales) :si \ x \geq 0, alors \ \Phi(x) = 0,5 + \Phi_0(x)si \ x , alors \ \Phi(x) = 0,5 - \Phi_0(-x)Soit T une variable aléatoire suivant la loi normale centrée réduite :pour tout \ x \in \R,\, P(T \leq x) = \Phi(x) et pour tout \ x \in \R^+,\, P(0 \leq T \leq x) = \Phi_0(x)pour tout couple \ x_1,\, x_2 de réels tels que \ x_1 \leq x_2, \ P(x_1 \leq T \leq x_2) = \Phi(x_2)- \Phi(x_1).Exemples numériquesÀ l'aide de la table ci-dessus, on obtient, pour la variable aléatoire précédente :\ P(0 \leq T \leq 1,7) = \Phi_0(1,7) \simeq 0,4554\ P(T \leq 1,7) = \Phi(1,7) = 0,5 + \Phi_0(1,7) \simeq 0,9554\ P(-0,3 \leq T \leq 1,7) = \Phi(1,7)- \Phi(-0,3) = 0,5 + \Phi_0(1,7) - 0,5 + \Phi_0(0,3) \simeq 0,5733 La loi normale généraleSoient \ T une variable aléatoire suivant la loi normale centrée réduite, et deux réels \mu,\, \sigma, où \ \sigma  0.On définit la variable aléatoire X = \sigma\, T + \mu, dont on note \ F la fonction de répartition.On a \mathrm(X) = \sigma\, \mathrm(T) + \mu = \mu et \mathrm(X) = \sigma^2\, \mathrm(T) = \sigma^2 puisque \ \mathrm(T) = 0 et \ \mathrm(T) = 1.Cherchons la loi de \ X : pour tout x \in \R,F(x) = P(X \leq x) = P(\sigma\, T + \mu \leq x) = P\left(T \leq \frac\right) = \Phi\left(\frac\right),puisque la fonction de répartition de \ T est \ \Phi.Ainsi, \ F est continûment (et même indéfiniment) dérivable : \ X suit une loi à densité, et la dérivée \ f de \ F est une densité de probabilité de cette variable aléatoire ; pour tout x \in \R,f(x) = F'(x) = \frac\, \Phi' \left(\frac\right) = \frac\, \varphi \left(\frac\right) = \frac\, \mathrm^\left(\frac\right)^2.Ceci légitime la définition suivante :DéfinitionOn appelle loi normale (ou gaussienne, ou de Laplace-Gauss) de paramètres \ \mu,\, \sigma^2 (où \ \sigma  0) la loi de probabilité définie par la densité \ f : \R \to \R^+, telle que pour tout x \in \R :f(x) = \frac\, \varphi \left(\frac\right) = \frac\, \mathrm^\left(\frac\right)^2.Notation: cette loi est notée \mathcal(\mu,\, \sigma^2)   La loi normale centrée réduite est notée \mathcal(0,\, 1).On peut énoncer plusieurs propriétés, compte tenu de ce qui précède (le dernier point se démontrant de manière analogue).PropriétésSoit une variable aléatoire \ X qui suit la loi normale \mathcal(\mu,\, \sigma^2). Alors :son espérance et sa variance existent et \ \mathrm(X) = \mu, \ \mathrm(X) = \sigma^2  0sa fonction de répartition \ F est telle que pour tout x \in \R,F(x) = \Phi\left(\frac\right)la variable aléatoire X^\star = \frac(X)(X), c'est-à-dire X^\star = \frac, suit la loi normale centrée réduitesi \ \alpha,\, \beta sont deux réels (\ \alpha \neq 0), alors la variable aléatoire \ \alpha\, X + \beta suit la loi normale \mathcal(\alpha\, \mu + \beta,\, \alpha^2\, \sigma^2)Soit une variable aléatoire \ X qui suit la loi normale \mathcal(\mu,\, \sigma^2). Alors la variable aléatoire  \exp(X)  (de loi dite log-normale) possède les propriétés suivantes:son espérance existe et vaut \ \mathrm\exp(X) = \exp\left( \mathrm(X) + \frac(X)\right) = \exp\left(\mu + \frac\right) sa variance existe et vaut \ \mathrm\exp(X) = \exp( 2 \mathrm(X) + \mathrm(X)) \left\mathrm(X)) - 1\right = \exp( 2 \mu + \sigma^2) (\exp(\sigma^2) - 1) Soit une variable aléatoire \ X suivant une loi normale \mathcal(\mu_X,\, \sigma_X^2) et \ Y suivant une loi normale \mathcal(\mu_Y,\, \sigma_Y^2). Alors, la divergence de Kullback-Leibler entre ces deux distributions est de la forme :D_(X\|Y) = \frac \left( \log \left( \frac \right) + \frac + \frac - 1 \right) Largeur à mi-hauteurLorsque l'on travaille sur une représentation graphique, on estime fréquemment la largeur de la gaussienne par sa largeur à mi-hauteur H'' (en anglais ''full width at half maximum, FWHM), qui est la largeur de la courbe à une altitude qui vaut la moitié de l'altitude du sommet. La largeur à mi-hauteur est proportionnelle à l'écart type :H = 2 \sqrt\ \sigma \simeq 2,3548 \sigma Le facteur 2 sert à prendre en compte l'extension de la gaussienne dans les valeurs négatives.Calcul de P(a ≤ X ≤ b)Les résultats précédents permettent de ramener tout calcul de probabilité relatif à la loi normale \mathcal(\mu,\, \sigma^2) à un calcul de probabilité relatif à la loi normale centrée réduite. On a vu qu'on dispose de tables donnant des approximations de valeurs de la fonction \ \Phi, tables qu'on utilise encore fréquemment, même si certaines calculatrices ou certains tableurs peuvent maintenant les remplacer.Si la variable aléatoire \ X suit la loi normale \mathcal(\mu,\, \sigma^2), et si \ a,\, b sont deux réels tels que \ a \leq b, on a :\ P(a \leq X \leq b) = F(b) - F(a) = \Phi\left(\frac\right) - \Phi\left(\frac\right)Cas d'un intervalle centré à la moyenne, plages de normalitéSi t est un réel positif,\ P(\mu - t\, \sigma \leq X \leq \mu + t\, \sigma) = \Phi(t) - \Phi(-t) = \Phi(t) - (1 - \Phi(t)) = 2\, \Phi(t) - 1lorsque \ P(\mu - t\, \sigma \leq X \leq \mu + t\, \sigma) = \alpha, où \ \alpha \in\, ]0,\, 1[,ce qui équivaut à \ 2\, \Phi(t) - 1 = \alpha, ou \ \Phi(t) = \frac,l'intervalle \ - t\, \sigma,\, \mu + t\, \sigma = - t\, \sigma,\, \mathrm(X) + t\, \sigma  est appelé plage de normalité au niveau de confiance \alpha(si par exemple, \alpha = 0, 95, on dit : "plage de normalité au niveau de confiance 95%" : en statistique, c'est un intervalle dans lequel se trouve 95% de la population lorsque la distribution est gaussienne).Exemples numériquesGrâce à la table précédente, on obtient :\ P(\mu - \sigma \leq X \leq \mu + \sigma) \simeq 0,6826 ;l'intervalle - \sigma,\, \mathrm(X) + \sigma  est la plage de normalité au niveau de confiance 68 %\ P(\mu - 0,5H \leq X \leq \mu + 0,5H) \simeq 0,76.. ;l'intervalle - 0,5H,\, \mathrm(X) + 0,5H  (H étant la largeur à mi-hauteur) est la plage de normalité au niveau de confiance 76 %\ P(\mu - 2\, \sigma \leq X \leq \mu + 2\, \sigma) \simeq 0,9544 ;l'intervalle - 2\, \sigma,\, \mathrm(X) + 2\, \sigma  est la plage de normalité au niveau de confiance 95 %\ P(\mu - 3\, \sigma \leq X \leq \mu + 3\, \sigma) \simeq 0,9974 ;l'intervalle - 3\, \sigma,\, \mathrm(X) + 3\, \sigma  est la plage de normalité au niveau de confiance 99 %Champ d'applicationnous montre que la loi binomiale tend vers la loi normale]] Le Théorème de Moivre-Laplace affirme la convergence d'une loi binomiale vers une loi de Gauss quand le nombre d'épreuves augmente. On peut alors utiliser la loi normale comme approximation d'une loi binomiale de paramètres (n'' ; ''p) pour n'' grand et ''p, 1 - p de même ordre de grandeur ; on approche alors cette loi binomiale par la loi normale ayant même espérance np et même variance np(1-p).On a dessiné ci-dessous :la loi binomiale de paramètres (12 ; 1/3) (diagramme en bâtons rouge) et la loi normale correspondante d'espérance 4 et de variance 8/3 (courbe verte)la loi binomiale de paramètres (60 ; 1/3) (diagramme en bâtons rouge) , et la loi normale correspondante d'espérance 20 et de variance 40/3 (courbe verte)Le mathématicien Carl Friedrich Gauss a introduit cette loi pour le calcul d'erreurs.En statistiques, de nombreux phénomènes suivent des distributions gaussiennes : données biométriques des individus (Adolphe Quételet).Critères et tests de normalitéCritères de normalitéLe recours à une distribution gaussienne est si fréquent qu'il peut finir par être abusif. Il faut alors rechercher des critères de normalité.Le premier critère, le plus simple, consiste à tracer l'histogramme ou le diagramme en bâtons de la distribution et à vérifier si le diagramme est en forme de « cloche ». Ce critère, subjectif, permet cependant d'éliminer une partie des distributions jugées alors non gaussiennes.Le critère suivant consiste à utiliser les plages de normalité ou intervalles de confiance. On a vu que si une distribution est gaussienne :68% de la population est dans l'intervalle -\sigma\, ;\, \overline+\sigma,76% de la population est dans l'intervalle -0,5H\, ;\, \overline+0,5H,95% de la population est dans l'intervalle -2\, \sigma\, ;\, \overline + 2\, \sigma,99% de la population est dans l'intervalle - 3\, \sigma\, ;\, \overline + 3\, \sigma.Lorsque ces pourcentages ne sont pas respectés, il y a fort à parier que la distribution n'est pas gaussienne.On peut aussi utiliser la droite de Henry, en particulier quand on possède peu de renseignements sur la distribution. La droite de Henry va permettre de porter un diagnostic sur la nature non gaussienne de la distribution, et, dans le cas où celle-ci a des chances d'être gaussienne, elle permet d'en déterminer la moyenne et l'écart type.Tests de normalitéIl existe également un grand nombre de :Tests basés sur la fonction de répartition empirique : Test de Kolmogorov-Smirnov et son adaptation le , ou le Tests basés sur les moments, comme le Test de Jarque Bera ou Test d'adéquation du χ²ou encore le Stabilité de la loi normale par la sommeLa somme de deux variables gaussiennes indépendantes est elle-même une variable gaussienne. Plus explicitement :Soient  X_1,\, X_2 deux variables aléatoires indépendantes suivant respectivement les lois  \mathcal(m_1,\, \sigma_1^2) et  \mathcal(m_2,\, \sigma_2^2).Alors, la variable aléatoire \ X_1 + X_2 suit la loi normale  \mathcal(m_1 + m_2,\, \sigma_1^2 + \sigma_2^2).Cette propriété se démontre directement (par convolution), ou indirectement (au moyen des fonctions caractéristiques).ExempleOn prend ici le gramme comme unité de masse. Si la masse du contenu d'une boîte de conserve suit la loi normale d'espérance 400 et de variance 25, et si celle du contenant suit la loi normale d'espérance 60 et de variance 4, alors (avec l'hypothèse, naturelle, d'indépendance) la masse totale de la boîte de conserve suit la loi normale d'espérance 460 et de variance 29 ; son écart type est environ 5, 4 grammes.Stabilité de la loi normale par la moyenneStabilité de la loi normale par la combinaisonMélange de populationsIl ne faut pas confondre la somme de deux variables gaussiennes indépendantes, qui reste une variable gaussienne, et le mélange de deux populations gaussiennes, qui n'est pas une population gaussienne (voir aussi modèle de mixture gaussienne).Un mélange constitué de2/3 d'individus dont la taille suit une loi normale de moyenne 160 cm et d'écart type 15 cm, de densité f1/3 d'individus dont la taille suit une loi normale de moyenne 130 cm et d'écart type 10 cm, de densité gsuit une loi de moyenne (2/3)×160+(1/3)×130 = 150 cm, mais non gaussienne, de densitéh'' = (2/3) ''f + (1/3) g.Sur la représentation graphique de la densité h, on peut apercevoir une double bosse : la distribution est bimodale.SimulationIl est possible de simuler, par exemple par ordinateur, un tirage aléatoire dont la loi est normale.Les logiciels ou les langages de programmation possèdent en général un générateur de nombres pseudo-aléatoires ayant une distribution uniforme sur ]0,1On cherche donc une fonction transformant ces nombres. De manière générale, on peut prendre la fonction réciproque de la fonction de répartition : en l'occurrence, si la variable aléatoire &lt;math&gt;U&lt;/math&gt; suit la loi uniforme sur 0,1[, alors la variable aléatoire \ \Phi^(U) suit la loi normale centrée réduite ; cependant, cette méthode est tout à fait malcommode, faute d'expressions simples des fonctions \ \Phi et \ \Phi^. En revanche, on peut facilement utiliser la méthode décrite ci-dessous.Cas de la loi normale à une dimensionPour simuler la loi normale à une dimension (celle qui a été étudiée jusqu'ici), on peut utiliser la méthode de Box-Muller dont voici le principe : Si U_1 et U_2 sont des variables aléatoires indépendantes qui suivent la loi uniforme sur ]0,1[, alors on démontre assez aisément que les variables aléatoires :T_=\sqrt\, \cos (2\pi U_)T_=\sqrt\, \sin (2\pi U_)suivent toutes deux la loi normale centrée réduite (et sont indépendantes).Les variables aléatoires X_1 = \mu + \sigma\, T_1 et X_2 = \mu + \sigma\, T_2 suivent donc toutes deux la loi normale \, \mathcal(\mu,\, \sigma^2), et indépendamment l'une de l'autre.Voir aussi Générateur de nombres aléatoires gaussiens, message de news:fr.sci.maths,  ; Generating Gaussian Random NumbersCas de la loi multinormaleLa loi multinormale ou loi normale sur \R^n étend la loi normale à un vecteur aléatoire X = (X_1,\, X_2,\dots,\, X_n) à valeurs dans \R^n.Elle est caractérisée par deux paramètres : un vecteur m de moyennes, et une matrice de variance-covariance V (carrée d'ordre n).Pour simuler une loi multinormale non dégénérée de paramètres m et V, on utilise la méthode suivante :Soit T un vecteur aléatoire à n composantes gaussiennes centrées réduites et indépendantes (la loi de T, multinormale, a pour moyenne le vecteur nul et pour matrice de variance-covariance la matrice identité).Soit L la matrice résultant de la factorisation de Cholesky de la matrice V.Alors, le vecteur aléatoire X=m+L T suit la loi multinormale de moyenne m et de variance-covariance V(on convient dans cette dernière relation d'identifier chaque élément de \R^n avec la matrice colonne de ses composantes en base canonique).Le calcul de l'intégrale de GaussOn trouvera ce calcul (utilisant une intégrale double) dans l'article sur l'intégrale de Gauss.AnnexesNotes et référencesArticles connexesLoi normale multidimensionnelleLoi log-normale où lnX suit une loi normale .Loi stable ou loi de Lévy tronquée, pour lequel la loi normale est un cas particulier pour le cas du paramètre alpha=2.Erreur (métrologie)StatistiquesProbabilitéLoi de probabilitéloi du χ²Loi de StudentNormale Catégorie:Fonctions spécialesar:توزيع احتمالي طبيعي az:Normal paylanma ca:Distribució normal cs:Normální rozdělení cy:Dosraniad normal da:Normalfordeling de:Normalverteilung en:Normal distribution eo:Normala distribuo es:Distribución normal fa:توزیع نرمال fi:Normaalijakauma gl:Distribución normal he:התפלגות נורמלית hr:Normalna raspodjela hu:Normális eloszlás id:Distribusi normal is:Normaldreifing it:Variabile casuale normale ja:正規分布 ko:정규분포 la:Distributio normalis lt:Normalusis skirstinys lv:Normālsadalījums nl:Normale verdeling no:Normalfordeling pl:Rozkład normalny pt:Distribuição normal ru:Нормальное распределение simple:Normal distribution sk:Normálne rozdelenie sl:Normalna porazdelitev sr:Нормална расподела su:Sebaran normal sv:Normalfördelning tr:Normal dağılım uk:Нормальний розподіл ur:معمول توزیع vi:Phân phối chuẩn zh:正态分布