In game theory, the Nash equilibrium (named after John Forbes Nash, who proposed it) is a solution concept of a game involving two or more players, in which each player is assumed to know the equilibrium strategies of the other players, and no player has anything to gain by changing only his or her own strategy (i.e., by changing unilaterally). If each player has chosen a strategy and no player can benefit by changing his or her strategy while the other players keep theirs unchanged, then the current set of strategy choices and the corresponding payoffs constitute a Nash equilibrium. In other words, to be a Nash equilibrium, each player must answer negatively to the question: "Knowing the strategies of the other players, and treating the strategies of the other players as set in stone, can I benefit by changing my strategy?"Stated simply, Amy and Bill are in Nash equilibrium if Amy is making the best decision she can, taking into account Bill's decision, and Bill is making the best decision he can, taking into account Amy's decision. Likewise, many players are in Nash equilibrium if each one is making the best decision that they can, taking into account the decisions of the others. However, Nash equilibrium does not necessarily mean the best cumulative payoff for all the players involved; in many cases all the players might improve their payoffs if they could somehow agree on strategies different from the Nash equilibrium (e.g. competing businessmen forming a cartel in order to increase their profits).HistoryThe concept of the Nash equilibrium (NE) in pure strategies was first developed by Antoine Augustin Cournot in his theory of oligopoly (1838). Firms choose a quantity of output to maximize their own profit. However, the best output for one firm depends on the outputs of others. A Cournot equilibrium occurs when each firm's output maximizes its profits given the output of the other firms, which is a pure-strategy NE. However, the modern game-theoretic concept of NE is defined in terms of mixed-strategies, where players choose a probability distribution over possible actions. The concept of the mixed strategy NE was introduced by John von Neumann and Oskar Morgenstern in their 1944 book The Theory of Games and Economic Behavior. However, their analysis was restricted to the very special case of zero-sum games. They showed that a mixed-strategy NE will exist for any zero-sum game with a finite set of actions. The contribution of John Forbes Nash in his 1951 article Non-Cooperative Games was to define a mixed strategy NE for any game with a finite set of actions and prove that at least one (mixed strategy) NE must exist.DefinitionsInformal definitionInformally, a set of strategies is a Nash equilibrium if no player can do better by unilaterally changing his or her strategy. As a heuristic, one can imagine that each player is told the strategies of the other players. If any player would want to do something different after being informed about the others' strategies, then that set of strategies is not a Nash equilibrium. If, however, the player does not want to switch (or is indifferent between switching and not) then the set of strategies is a Nash equilibrium.The Nash equilibrium may sometimes appear non-rational in a third-person perspective. This is because it may happen that a Nash equilibrium is not pareto optimal.The Nash-equilibrium may also have non-rational consequences in sequential games because players may "threat" each other with non-rational moves. For such games the Subgame perfect Nash equilibrium may be more meaningful as a tool of analysis.Formal definitionLet (S, f) be a game, where Si is the strategy set for player i'', ''S=S1 X S2 ... X Sn is the set of strategy profiles and f=(f1(x), ..., fn(x)) is the payoff function. Let x-i be a strategy profile of all players except for player i''. When each player ''i \in  chooses strategy xi resulting in strategy profile x = (x1, ..., xn) then player i'' obtains payoff ''fi(x). Note that the payoff depends on the strategy profile chosen, i.e. on the strategy chosen by player i'' as well as the strategies chosen by all the other players. A strategy profile ''x* \in S is a Nash equilibrium (NE) if no unilateral deviation in strategy by any single player is profitable for that player, that is\forall i,x_i\in S_i, x_i \neq x^*_ : f_i(x^*_, x^*_) \geq f_i(x_,x^*_).A game can have a pure strategy NE or an NE in its mixed extension (that of choosing a pure strategy stochastically with a fixed frequency). Nash proved that, if we allow mixed strategies (players choose strategies randomly according to pre-assigned probabilities), then every n-player game in which every player can choose from finitely many strategies admits at least one Nash equilibrium.When the inequality above holds strictly (with  instead of \geq) for all players and all feasible alternative strategies, then the equilibrium is classified as a strict Nash equilibrium. If instead, for some player, there is exact equality between x^*_i and some other strategy in the set S, then the equilibrium is classified as a weak Nash equilibrium.Examples=== Competition game ===A competition gamePlayer 2 chooses '0'Player 2 chooses '1'Player 2 chooses '2'Player 2 chooses '3'Player 1 chooses '0'0'', ''02'', ''-22'', ''-22'', ''-2Player 1 chooses '1'''-2'', 21'', ''13'', ''-13'', ''-1Player 1 chooses '2'''-2'', 2''-1'', 32'', ''24'', ''0Player 1 chooses '3'''-2'', 2''-1'', 30'', ''43'', ''3This can be illustrated by a two-player game in which both players simultaneously choose a whole number from 0 to 3 and they both win the smaller of the two numbers in points. In addition, if one player chooses a larger number than the other, then he/she has to give up two points to the other. This game has a unique pure-strategy Nash equilibrium: both players choosing 0 (highlighted in light red). Any other choice of strategies can be improved if one of the players lowers his number to one less than the other player's number. In the table to the left, for example, when starting at the green square it is in player 1's interest to move to the purple square by choosing a smaller number, and it is in player 2's interest to move to the blue square by choosing a smaller number. If the game is modified so that the two players win the named amount if they both choose the same number, and otherwise win nothing, then there are 4 Nash equilibria (0,0...1,1...2,2...and 3,3).Coordination gameA coordination gamePlayer 2 adopts strategy 1Player 2 adopts strategy 2Player 1 adopts strategy 1A'', ''AB'', ''CPlayer 1 adopts strategy 2C'', ''BD'', ''DThe coordination game is a classic (symmetric) two player, two strategy game, with the payoff matrix shown to the right, where the payoffs satisfy AC and DB. The players should thus coordinate, either on A'' or on ''D, to receive a high payoff. If the players' choices do not coincide, a lower payoff is rewarded. An example of a coordination game is the setting where two technologies are available to two firms with compatible products, and they have to elect a strategy to become the market standard. If both firms agree on the chosen technology, high sales are expected for both firms. If the firms do not agree on the standard technology, few sales result. Both strategies are Nash equilibria of the game.Driving on a road, and having to choose either to drive on the left or to drive on the right of the road, is also a coordination game. For example, with payoffs 100 meaning no crash and 0 meaning a crash, the coordination game can be defined with the following payoff matrix:The driving gameDrive on the LeftDrive on the RightDrive on the Left100, 1000, 0Drive on the Right0, 0100, 100In this case there are two pure strategy Nash equilibria, when both choose to either drive on the left or on the right. If we admit mixed strategies (where a pure strategy is chosen at random, subject to some fixed probability), then there are three Nash equilibria for the same case: two we have seen from the pure-strategy form, where the probabilities are (0%,100%) for player one, (0%, 100%) for player two; and (100%, 0%) for player one, (100%, 0%) for player two respectively. We add another where the probabilities for each player is (50%, 50%).Prisoner's dilemma (note differences in the orientation of the payoff matrix) The Prisoner's Dilemma has the same payoff matrix as depicted for the Coordination Game, but now C  A  D  B. Because C  A and D  B, each player improves his situation by switching from strategy #1 to strategy #2, no matter what the other player decides. The Prisoner's Dilemma thus has a single Nash Equilibrium: both players choosing strategy #2 ("betraying"). What has long made this an interesting case to study is the fact that D , can also be applied to Nash equilibria.A Nash equilibrium for a mixed strategy game is stable if a small change (specifically, an infinitesimal change) in probabilities for one player leads to a situation where two conditions hold:the player who did not change has no better strategy in the new circumstancethe player who did change is now playing with a strictly worse strategyIf these cases are both met, then a player with the small change in his mixed-strategy will return immediately to the Nash equilibrium. The equilibrium is said to be stable. If condition one does not hold then the equilibrium is unstable. If only condition one holds then there are likely to be an infinite number of optimal strategies for the player who changed. John Nash showed that the latter situation could not arise in a range of well-defined games.In the "driving game" example above there are both stable and unstable equilibria. The equilibria involving mixed-strategies with 100% probabilities are stable. If either player changes his probabilities slightly, they will be both at a disadvantage, and his opponent will have no reason to change his strategy in turn. The (50%,50%) equilibrium is unstable. If either player changes his probabilities, then the other player immediately has a better strategy at either (0%, 100%) or (100%, 0%).Stability is crucial in practical applications of Nash equilibria, since the mixed-strategy of each player is not perfectly known, but has to be inferred from statistical distribution of his actions in the game. In this case unstable equilibria are very unlikely to arise in practice, since any minute change in the proportions of each strategy seen will lead to a change in strategy and the breakdown of the equilibrium.A Coalition-Proof Nash Equilibrium (CPNE) (similar to a Strong Nash Equilibrium) occurs when players cannot do better even if they are allowed to communicate and collaborate before the game. Every correlated strategy supported by iterated strict dominance and on the Pareto frontier is a CPNE. Further, it is possible for a game to have a Nash equilibrium that is resilient against coalitions less than a specified size, k. CPNE is related to the theory of the core.== Occurrence == If a game has a unique Nash equilibrium and is played among players under certain conditions, then the NE strategy set will be adopted. Sufficient conditions to guarantee that the Nash equilibrium is played are:The players all will do their utmost to maximize their expected payoff as described by the game.The players are flawless in execution.The players have sufficient intelligence to deduce the solution.The players know the planned equilibrium strategy of all of the other players.The players believe that a deviation in their own strategy will not cause deviations by any other players.There is common knowledge that all players meet these conditions, including this one. So, not only must each player know the other players meet the conditions, but also they must know that they all know that they meet them, and know that they know that they know that they meet them, and so on.Where the conditions are not metExamples of game theory problems in which these conditions are not met:The first condition is not met if the game does not correctly describe the quantities a player wishes to maximize. In this case there is no particular reason for that player to adopt an equilibrium strategy. For instance, the prisoner’s dilemma is not a dilemma if either player is happy to be jailed indefinitely.Intentional or accidental imperfection in execution. For example, a computer capable of flawless logical play facing a second flawless computer will result in equilibrium. Introduction of imperfection will lead to its disruption either through loss to the player who makes the mistake, or through negation of the 4th 'common knowledge' criterion leading to possible victory for the player. (An example would be a player suddenly putting the car into reverse in the game of 'chicken', ensuring a no-loss no-win scenario).In many cases, the third condition is not met because, even though the equilibrium must exist, it is unknown due to the complexity of the game, for instance in Chinese chessNash proved that a perfect NE exists for this type of finite extensive form game – it can be represented as a strategy complying with his original conditions for a game with a NE. Such games may not have unique NE, but at least one of the many equilibrium strategies would be played by hypothetical players having perfect knowledge of all 10150 game trees.. Or, if known, it may not be known to all players, as when playing tic-tac-toe with a small child who desperately wants to win (meeting the other criteria).The fourth criterion of common knowledge may not be met even if all players do, in fact, meet all the other criteria. Players wrongly distrusting each other's rationality may adopt counter-strategies to expected irrational play on their opponents’ behalf. This is a major consideration in “Chicken” or an arms race, for example.Where the conditions are metDue to the limited conditions in which NE can actually be observed, they are rarely treated as a guide to day-to-day behaviour, or observed in practice in human negotiations. However, as a theoretical concept in economics, and evolutionary biology the NE has explanatory power. The payoff in economics is money, and in evolutionary biology gene transmission, both are the fundamental bottom line of survival. Researchers who apply games theory in these fields claim that agents failing to maximize these for whatever reason will be competed out of the market or environment, which are ascribed the ability to test all strategies. This conclusion is drawn from the "stability" theory above. In these situations the assumption that the strategy observed is actually a NE has often been borne out by research.NE and non-credible threatsThe nash equilibrium is a superset of the subgame perfect nash equilibrium. The subgame perfect equilibrium in addition to the Nash Equilibrium requires that the strategy also is a Nash equilibrium in every subgame of that game. This eliminates all non-credible threats, that is, strategies that contain non-rational moves in order to make the counter-player change his strategy.The image to the right shows a simple sequential game that illustrates the issue with subgame imperfect Nash equilibria. In this game player one chooses left(L) or right®, which is followed by player two being called upon to be kind (K) or unkind (U) to player one, However, player two only stands to gain from being unkind if player one goes left. If player one goes right the rational player two would de facto be kind to him in that subgame. However, The non-credible threat of being unkind at 2(2) is still part of the blue (L, (U,U)) nash equilibrium. Therefore, if rational behavior can be expected by both parties the subgame perfect Nash equilibrium may be a more meaningful solution concept when such dynamic inconsistencies arise.Proof of existenceAs above, let \sigma_ be a mixed strategy profile of all players except for player i. We can define a best response correspondence for player i, b_i. b_i is a relation from the set of all probability distributions over opponent player profiles to a set of player i's strategies, such that each element ofb_i(\sigma_)is a best response to \sigma_. Defineb(\sigma) = b_1(\sigma_) \times b_2(\sigma_) \times \cdots \times b_n(\sigma_).One can use the Kakutani fixed point theorem to prove that b has a fixed point. That is, there is a \sigma^* such that \sigma^* \in b(\sigma^*). Since b(\sigma^*) represents the best response for all players to \sigma^*, the existence of the fixed point proves that there is some strategy set which is a best response to itself. No player could do any better by deviating, and it is therefore a Nash equilibrium.When Nash made this point to John von Neumann in 1949, von Neumann famously dismissed it with the words, "That's trivial, you know. That's just a fixed point theorem." (See Nasar, 1998, p. 94.)Alternate proof using the [[Brouwer fixed point theorem]]We have a game G=(N,A,u) where N is the number of players and A = A_1 \times \ldots \times A_N is the action set for the players. All of the actions sets A_i are finite. Let \Delta = \Delta_1 \times \ldots \times \Delta_N denote the set of mixed strategies for the players. The finiteness of the A_is insures the compactness of \Delta.We can now define the gain functions. For a mixed strategy \sigma \in \Delta, we let the gain for player i on action a \in A_i beGain_i(\sigma,a) = \max \) - u_i(\sigma_, \sigma_)\The gain function represents the benefit a player gets by unilaterally changing his strategy. We now define g = (g_1,\ldots,g_N) whereg_i(\sigma)(a) = \sigma_i(a) + Gain_i(\sigma,a)for \sigma \in \Delta, a \in A_i. We see that\sum_ g_i(\sigma)(a) = \sum_ \sigma_i(a) + Gain_i(\sigma,a)= 1 + \sum_ Gain_i(\sigma,a)  0We now use g to define f: \Delta \rightarrow \Delta as follows. Letf_i(\sigma)(a) = \frac g_i(\sigma)(b) for a \in A_i. It is easy to see that each f_i is a valid mixed strategy in \Delta_i. It is also easy to check that each f_i is a continuous function of \sigma, and hence f is a continuous function. Now \Delta is the cross product of a finite number of compact convex sets, and so we get that \Delta is also compact and convex. Therefore we may apply the Brouwer fixed point theorem to f. So f has a fixed point in \Delta, call it \sigma^*.I claim that \sigma^* is a Nash Equilibrium in G. For this purpose, it suffices to show that\forall 1 \leq i \leq N, ~ \forall a \in A_i, ~ Gain_i(\sigma^*,a) = 0 \text  This simply states the each player gains no benefit by unilaterally changing his strategy which is exactly the necessary condition for being a Nash Equilibrium.Now assume that the gains are not all zero. Therefore, \exists i, 1 \leq i \leq N, and a \in A_i such that Gain_i(\sigma^*, a)  0. Note then that\sum_ g_i(\sigma^*, a) = 1 + \sum_ Gain_i(\sigma^*,a)  1  So let C = \sum_ g_i(\sigma^*, a). Also we shall denote Gain(i,\cdot) as the gain vector indexed by actions in A_i. Since f(\sigma^*) = \sigma^* we clearly have that f_i(\sigma^*) = \sigma^*_i. Therefore we see that\sigma^*_i = \frac g_i(\sigma^*)(a) \Rightarrow \sigma^*_i = \frac \Rightarrow C\sigma^*_i = \sigma^*_i + Gain_i(\sigma^*,\cdot) \left(C-1\right)\sigma^*_i = Gain_i(\sigma^*,\cdot) \Rightarrow \sigma^*_i = \left(\frac\right)Gain_i(\sigma^*,\cdot) Since C  1 we have that \sigma^*_i is some positive scaling of the vector Gain_i(\sigma^*,\cdot). Now I claim that\sigma^*_i(a)(u_i(a_i, \sigma^*_) - u_i(\sigma^*_i, \sigma^*_)) = \sigma^*_i(a)Gain_i(\sigma^*, a) \forall a \in A_i. To see this, we first note that if Gain_i(\sigma^*, a)  0 then this is true by definition of the gain function. Now assume that Gain_i(\sigma^*, a) = 0. By our previous statements we have that\sigma^*_i(a) = \left(\frac\right)Gain_i(\sigma^*, a) = 0  and so the left term is zero, giving us that the entire expression is 0 as needed.So we finally have that0 = u_i(\sigma^*_i, \sigma^*_) - u_i(\sigma^*_i, \sigma^*_)  =  \left(\sum_ \sigma^*_i(a)u_i(a_i, \sigma^*_)\right) - u_i(\sigma^*_i, \sigma^*_) =  \sum_ \sigma^*_i(a) (u_i(a_i, \sigma^*_) - u_i(\sigma^*_i, \sigma^*_)) = \sum_ \sigma^*_i(a) Gain_i(\sigma^*, a) \quad \text = \sum_ \left( C -1 \right) \sigma^*_i(a)^2 &gt; 0where the last inequality follows since \sigma^*_i is a non-zero vector. But this is a clear contradiction, so all the gains must indeed be zero. Therefore \sigma^* is a Nash Equilibrium for G as needed.See alsoAdjusted Winner procedureBest responseConflict resolution researchEvolutionarily stable strategyGame theoryGlossary of game theoryHotelling's lawMexican StandoffMinimax theoremOptimum contract and par contractPrisoner's dilemmaRelations between equilibrium conceptsSolution conceptEquilibrium selectionStackelberg competitionSubgame perfect Nash equilibriumWardrop's principleComplementarity theoryReferencesGame Theory textbooks. Suitable for undergraduate and business students.Fudenberg, Drew and Jean Tirole (1991) Game Theory MIT Press.Morgenstern, Oskar and John von Neumann (1947) The Theory of Games and Economic Behavior Princeton University Press. A modern introduction at the graduate level.Original PapersNash, John (1950) "Equilibrium points in n-person games" Proceedings of the National Academy of Sciences 36(1):48-49.Nash, John (1951) "Non-Cooperative Games" The Annals of Mathematics 54(2):286-295.Other ReferencesMehlmann, A. The Game's Afoot! Game Theory in Myth and Paradox, American Mathematical Society (2000).Nasar, Sylvia (1998), "A Beautiful Mind", Simon and Schuster, Inc.== Notes == External linksComplete Proof of Existence of Nash EquilibriaCategory:Game theory Category:Fixed pointsca:Equilibri de Nash cs:Nashova rovnováha da:Nash-ligevægt de:Nash-Gleichgewicht es:Equilibrio de Nash fa:تعادل نش fr:Équilibre de Nash gl:Equilibrio de Nash ko:내시 균형 it:Equilibrio di Nash he:שיווי משקל נאש lt:Nešo pusiausvyra hu:Nash-egyensúly nl:Nash-evenwicht ja:ナッシュ均衡 no:Nash-likevekt pl:Równowaga Nasha pt:Equilíbrio de Nash ro:Echilibru Nash ru:Равновесие Нэша sr:Нешов еквилибријум fi:Nashin tasapaino tr:Nash dengesi uk:Рівновага Неша zh:納什均衡點